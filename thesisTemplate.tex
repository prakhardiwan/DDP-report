\documentclass[a4paper,12pt, final]{report}
\usepackage{graphicx}
\usepackage{float}
\usepackage{url}
%\usepackage[nomain,acronym,xindy,toc]{glossaries} % nomain, if you define glossaries in a file, and you use \include{INP-00-glossary}
%\makeglossaries
%\usepackage[xindy]{imakeidx}
%\makeindex
%\usepackage[section]{placeins}
\renewcommand\bibname{References}
\usepackage[utf8]{inputenc}
%\usepackage{algorithm2e}
%\usepackage{wrapfig}
\usepackage{epsfig}
%\usepackage{hyperref}
\usepackage[hidelinks]{hyperref} % To Hide the box around links
\renewcommand\bibname{References}
%\usepackage{algorithm2e}
\usepackage{color}
\usepackage{textcomp}
\usepackage{acronym}
\usepackage[top=0.5in, bottom=1in, left=1in, right=1in]{geometry}
\usepackage{xcolor}
\definecolor{dark-red}{rgb}{0.4,0.15,0.15}
\definecolor{dark-blue}{rgb}{0.15,0.15,0.4}
\definecolor{medium-blue}{rgb}{0,0,0.5}

\newcommand{\BigO}[1]{\ensuremath{\operatorname{O}\bigl(#1\bigr)}}
\parindent 8pt
\begin{document}
  \thispagestyle{empty}
  \vspace*{1cm}
  {\centering     
  \textbf{\LARGE Heterogeneous-ISA Polymorphic Architecture: Exploiting ILP-TLP tradeoffs above ISA affinity}\\
  \vspace{1.20cm}
  %\it
  %\vspace{.5cm}
  %\rm
  \textbf{\large Dual Degree Project Stage 1 Report}\\
  \vspace{1cm}
  {Submitted in partial fulfillment of the requirements}\\
  \vspace{0.25cm}
  {for the}\\
  \vspace{1cm}
  \textbf{Dual Degree Programme}\\
  \vspace{1.50cm}
  {by}\\
  \vspace{0.20cm}
  \textbf{\large Prakhar Diwan}\\
  \vspace{0.25cm}
  \textbf{\large (Roll No. 180100083)}\\
  \vspace{1.8cm}
  {Under the guidance of}\\
  \vspace{0.20cm}
  \textbf{\large Prof. Virendra Singh}\\
    \vspace{0.30cm}
  \vspace{1.450cm}
    \begin{figure}[htb]
    \begin{center}
    \includegraphics[height=1.5in,width=1.5in]{iitblogo.png}
    \end{center}
    \end{figure}

    
  {\textbf{Department of Electrical Engineering}}\\
  {\textbf{Indian Institute of Technology Bombay}}\\
  {\textbf{October 2022}}
 
 }
 
\renewcommand{\abstractname}{Acknowledgement}
\begin{abstract}
I express my gratitude to my guide, Prof. Virendra Singh for allowing me to work on this topic. I am also grateful to Nirmal Kumar Boran and other members of Computer Architecture \& Dependable Systems Lab (CADSL) for their support.  
\\\\
\\\\
\\\\
Prakhar Diwan\\
Electrical Engineering\\
IIT Bombay\\\

\end{abstract}


\clearpage 
\renewcommand{\abstractname}{Abstract} 
\abstract{
% Part on Heterogoneity in microarchitecture... 
Modern workloads demand a microarchitecture that can adapt to software diversity by exploiting instruction level parallelism (ILP) from their sequential and thread level parallelism (TLP) from their parallel phases to achieve high performance and energy efficiency. After multi-core’s inception, various solutions have been proposed to utilize heterogeneity and reconfigurability in microarchitecture. Prior research has shown ISA as another dimension of heterogeneity, providing significant performance and energy efficiency gains over single-ISA heterogeneous architectures. \\
\indent This work proposes a reconfigurable heterogeneous-ISA multi-core architecture, which exploits the heterogeneity in ISA and microarchitecture for achieving high performance and energy efficiency. It will schedule the workload phases on optimal configuration (re-configured at runtime) with respect to ISA affinity \& ILP-TLP trade-offs, hence providing significant is aimed for both single \& multithreaded workloads.
}

\tableofcontents
  \addcontentsline{toc}{chapter}{\listfigurename}
  \listoffigures
%  \printglossaries

%\newglossaryentry{ILP}
%{name = ILP,
%description = Instruction Level Parallelism}
\chapter{Introduction}
During the last decades of the previous century, the central aim of microprocessor technology was to make the core faster. Performance was improved through semiconductor technology advancements and architectural innovations. However, by the end of the last century, the power density became equal to that of the hot plate, restricting the further increase in frequency for performance. 
\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\linewidth]{homogeneous-mc.png}
    \caption{Homogeneous Multicore}
    \label{homo-mc}
\end{figure}
\indent 
The above limitation, termed as” power wall” forced the designers to shift to novel architectures. Researchers came up with multi-core systems to better cater to the need of applications. Overall performance was improved by exploiting Thread Level Parallelism (TLP) of multithreaded workloads through multiple cores. But these improvements saturated with single-threaded fraction of workloads becoming the bottleneck\cite{oldamdahl}. Also, the move to various cores led to an increase in energy consumption.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\linewidth]{single-isa-heterogeneous-mc.png}
    \caption{Single-ISA Heterogeneous Multicore}
    \label{sing-isa-hetero}
\end{figure}
\indent The initial proposed multicore architecture consisted of identical cores (Figure \ref{homo-mc}). Prior research has shown that exploiting heterogeneity is beneficial for a system's performance\cite{kumarheteroperf} \& power\cite{kumarheteropower}. Architects utilized the heterogeneity in two dimensions, the first was using specialized cores for certain workloads (e.g., SIMD support), and the second was using cores with different microarchitectures (Figure \ref{sing-isa-hetero}) based on workload's needs, to extract high performance \& energy efficiency.\\\\
\indent Till early 2010s, the heterogeneity exploration was limited to single-ISA due to the high migration cost between heterogeneous-ISA systems. DeVuyst et al. \cite{DeVuystVT12} solves the problem of migration between heterogeneous-ISA cores, and Venkat et al. \cite{venkat} highlighted the benefits brought by heterogeneous-ISA multicore (Figure \ref{hetero-isa-mc}).
\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\linewidth]{hetero-isa-mc.png}
    \caption{Heterogeneous-ISA Multicore}
    \label{hetero-isa-mc}
\end{figure}
\indent Another direction of research for improving single-threaded performance in multi-core systems was reconfigurable chip multiprocessors, where a group of independent cores can dynamically morph into a large core. These architectures could exploit Instruction Level Parallelism (ILP) in sequential phases of code by using the large core and effectively utilizing TLP from parallel phases by operating as small independent cores. These types of architectures are unexplored for heterogeneous-ISA cores.  \\\\
\indent Heterogeneous-ISA Dynamic Core (HIDC) has already been proposed, which exploits ISA (ARM, X86) and microarchitectural heterogeneity. The next chapter describes the research on dynamic \& heterogeneous multi-core architectures. Heterogeneous-ISA Dynamic Multi-core (HIDM) architecture is proposed to obtain more benefits from heterogeneity. It is a reconfigurable multi-core architecture aimed at achieving high performance \& energy efficiency. It is expected to perform well for single-threaded (SPEC CPU2006 suite \cite{speccpu}) as well as multithreaded workloads (PARSEC suite \cite{parsec}) by dynamically catering to ILP \& TLP needs.
\chapter{Literature Review}
This chapter describes the previous work on heterogeneous multi-core architectures. The first section gives insight into various ways microarchitectural heterogeneity has been exploited by summarizing some proposed ideas. The second section discusses proposals associated with ISA heterogeneity: solution to migration between heterogeneous ISA cores, harnessing performance and energy benefits from ISA diversity, and claims towards ISA homogeneity. 
\section{Heterogeneity in Microarchitecture}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\linewidth]{composite-cores-arch.png}
    \caption{Composite Cores Architecture}
    \label{composite-arch}
\end{figure}
% Composite Cores.. 
Lukefahr et al. \cite{lukefahr2012composite} proposed Composite Cores, an architecture which reduced migration overheads by accommodating heterogeneity within a core. The core consisted of a big (out-of-order) and a little (in-order) compute $\mu$engines (Figure \ref{composite-arch}). Both shared most of the architectural state leading to reduction in data transfer during migration between them, which led to lower switching overheads. This enabled fine-grained matching of application characteristics. An online reactive controller is used for making switching decisions, aiming to maximize energy savings under user configurable performance degradation constraint. It uses a linear regression model to predict CPI (cycles per instruction) for the $\mu$engine not being used in the current phase, and compares the CPI difference against the dynamic CPI threshold, if larger then execution is done on big $\mu$engine else on little $\mu$engine. %Overall 18\% energy savings were reported with performance degradation limited at 5\%. \\\\
\\
% Morph Cores.. 
\indent Suleman et al. \cite{suleman2012morphcore} came up with the idea of MorphCore, an adaptive core microarchitecture to achieve high performance for single-threaded code and high throughput for multi-threaded code with no energy overheads. A large 2-way SMT (simultaneous multi-threading) out-of-order (OoO) core (capable of exploiting ILP) is used as the base substrate. Upon it minimal modifications are done to dynamically form a 8 SMT in-order (InO) core. Hence it provides two modes of execution (Figure \ref{morph-arch}): OoO and InO, and uses OoO mode (2-way SMT OoO core) for single-threaded code to provide high performance of a traditional OoO core with minimal degradation. For multithreaded code, it uses the InO mode (8-way SMT InO core) which provides same or better performance as an OoO core \cite{hily1999} and consumes less power. Due to no migration of instructions and data needed, switching overhead was negligible. % Over a 2-way SMT OoO core MorphCore leads to 10\% performance improvement and 22\% reduction in energy-delay squared product. 
\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\linewidth]{morph-uarch.png}
    \caption{MorphCore Microarchitecture}
    \label{morph-arch}
\end{figure}
% Core Fusion ..
\indent Ipek et al. \cite{ipek2007core} presented core fusion, a reconfigurable chip multiprocessor (CMP) architecture which empowers groups of fundamentally independent CMP cores with the ability to "fuse" into a large CPU on demand from application. To effectively exploit ILP from sequential phases of application, it uses the fused mode configuration to create a large core, and for parallel phases it utilizes independent mode (base multicore). It is a fully hardware-based solution which uses hints from applications itself for making reconfiguration decisions. The CMP architecture  consists of eight two-issue OoO cores
\begin{figure}[H]
    \centering
    \includegraphics[width=0.4\linewidth]{corefusion-architecture.png}
    \caption{Core Fusion Conceptual Floorplan}
    \label{corefusion-arch}
\end{figure}
\noindent with private L1-i and L1-d caches and common L2 cache, the figure \ref{corefusion-arch} shows an example configuration of core fusion: one eight-issue (group of four CMP cores), one four-issue (group of two CMP cores) and two two-issue cores. Based on results shown for sequential, parallel and incrementally parallelized workloads, it was concluded that core fusion accommodates software diversity gracefully. 
%\begin{figure}[H]
%    \centering
%    \includegraphics[width=0.5\linewidth]{bahurupi-architecture.png}
%    \caption{Bahurupi Architecture}
%    \label{bahurupi-arch}
%\end{figure}
% Bahurupi .. 
\indent Pricopi et al. \cite{pricopi2012bahurupi} proposed Bahurupi, another reconfigurable homogeneous multicore architecture (comprising identical 2-way OoO cores), with aim to satisfy the conflicting demands of ILP and TLP put forth by workloads comprising fractions of parallel and sequential codes. A high ILP application can be accelerated by execution on a large core dynamically composed of four CMP-cores, a medium ILP application was scheduled on a 2-core coalition and low ILP applications were run on individual CMP cores. This architecture utilized a distributed execution model (compiler-hardware mixed solution) and achieved performance of equivalent fetch width complex OoO superscalar core without paying for complex hardware and associated energy inefficiency. % It's quad-core cluster reported 17\% and 43\% improvement in performance and energy consumption respectively compared to 8-way OoO core on embedded benchmark applications.
\section{Heterogeneity in ISA}
% How execution migration become possible.. 2012 DeVuyst
Devuyst et al. \cite{DeVuystVT12} claimed ISA diversity as an important dimension to gain performance using heterogeneity in cores. Multiple reasons for migration need were mentioned such as higher priority process being scheduled to high performance core with its currently executing process migrated to energy-efficient core or the process from high performance is switched to energy efficient core in battery saver mode. Authors listed various methods used during heterogeneous-ISA migration to reduce the overhead. They have modified compiler back end significantly to produce programs that keep most of their state in architectural neutral form. For maintaining stack consistency a stack transformer is used during migration. And for enabling instantaneous migration a binary translator is modified as required by the work and utilized. \\
\indent Venkat et al. \cite{venkat} carried out the design space exploration for finding optimal design to propose a heterogeneous-ISA CMP for general purpose computing.
Various parameters affected by ISA diversity and their impact on performance was analyzed. The program was migrated between different ISA cores at equivalence points. In case not at equivalence point, the program is binary translated to the target ISA (to be migrated to) till the nearest equivalence point is reached in execution. Authors examined phase wise affinity for various program phases and obtained execution times taken for switching between different ISA cores. Upon scheduling the program phases on the best-suited core using oracle scheduler, improvements of 20.8\% in performance and 23\% in energy efficiency were observed over single-ISA design. \\
% Harnessing ISA diversity work.. add some results here.. 
\indent To harness maximum benefits from ISA heterogeneity, dynamic determination of affine ISA for the next phase of the program is necessary. Boran et al. \cite{perfcadsl} proposed a performance model for estimating execution time of heterogeneous ISA system. They extend the model further for making dynamic coarse-grained \cite{coarsecadsl} and fine-grained \cite{finecadsl} schedulers for heterogeneous-ISA systems.\\
%schedulers for runtime execution 
% Power struggles.. need to criticize the paper's result and conclude that ISA heterogeneity does matter.. 
\indent Blem et al. \cite{blempower} tried to find if the ISA plays an intrinsic role in performance and energy efficiency of the implemented system. For this authors performed detailed experiments by running real applications from various workloads on real hardware, and analysed the measurements to claim that ISA being RISC or CISC doesn't matter. However, this is not true as: using real hardware led to microarchitecural differences among considered systems, the platform utilized was not uniform across the four implementations, no ISA-specific compiler optimizations were performed for binaries, approximate scaling models have been used for frequency and technology nodes, plus these don't consider the type of transistor technology used like MOSFET, FinFET, CasFET etc. and many other reasons. Authors themselves listed multiple other infrastructural limitations in the paper. The claim made is weak as ARM and X86 systems aren't provided equal stages to be compared justly. \\
\indent The next chapter describes the proposed work: introducing the problem, completed work and work to be done.
\chapter{Proposed Work}
\section{Introduction}
Based on the observations from the literature review, Heterogeneous-ISA Dynamic Multi-core (HIDM), a reconfigurable CMP architecture is proposed to achieve high performance & energy efficiency by meeting ILP-TLP & ISA affinity needs at runtime. ARM and X86 are the 2 ISAs considered based on their current popularity. As the base core, we will use Heterogeneous ISA Dynamic Core’s (8-way OoO) smaller version (2-way OoO). For analyzing the performance of merged cores, we will be using corresponding multiplied width cores, like a group of 2 2-way OoO cores modeled using a 4-way core. This is conservative based on results from Bahurupi \cite{pricopi2012bahurupi}. \\
\indent Another proposal is to make each of the 2-way OoO cores into an 8-way SMT InO core for highly threaded applications, which has been shown by Suleman et al. \cite{suleman2012morphcore}. This will help in extending the performance and energy benefits of reconfigurability for a higher number of threads (32 for a four-core system). 
\section{Completed Work}
I conducted an extensive literature review on various multi-core architectures, installed the gem5 simulator \cite{gem5}, and ran simple experiments for familiarization, completed the setup of the full system mode simulation environment for \texttt{ARM} and \texttt{X86} configurations. \\
\indent I compiled the original 13 workloads from PARSEC \cite{parsec} suite using \texttt{gcc 5.5.0} for \texttt{ARM} and \texttt{X86} ISAs. I faced issues with compilation of some benchmarks, as the suite was last updated in 2011 where they used \texttt{gcc 4.2.1} (unsupported). Also as majority of benchmarks use the \texttt{pthreads} library I have chosen to use it, but it doesn't support \texttt{freqmine} benchmark. As a result some of the benchmarks will be missing in analysis from the 13 original benchmarks. \\ 
\indent For choosing the optimal configuration in reconfigurable multi-core architecture, it is required to obtain the active number of threads at runtime, based on which scheduling is done, as in work by Suleman et al. \cite{suleman2012morphcore}. I performed an exhaustive search inside gem5 documentation and the internet to obtain this information by modifying gem5. During the investigation, I backtraced the \texttt{activateContext} and \texttt{suspendContext} functions, which led to various functions, ending with a stream of calls from shared libraries. I investigated the functions, but it led nowhere as the kernel handles the thread scheduling and has thread-related information; and in full system mode, the kernel is provided by the user as an unmodified binary along with the disk image. Hence, recovery of the active number of threads from gem5 FS mode wasn’t possible. But through modifications in gem5, I could obtain the number of physical threads (same as the number of active cores) at runtime.  \\
\indent Then I made minimal modifications to the benchmarks to incorporate a thread counter which decremented on every thread termination, thus depicting the number of live threads at runtime. The counter is a global variable set to the number of threads created by the user and is decremented in the critical section formed using \texttt{mutex} locks and unlocks from \texttt{pthread} library. This addition made a negligible difference in results, as was confirmed from a test run of \texttt{blackscholes} benchmark with medium data-set on \texttt{ARM} simulated machine. I have tested the approach for counting threads on \texttt{blackscholes, bodytrack \& canneal} benchmarks. \\
\indent For the X86 full system (FS) simulations I used an available disk image with the compiled binaries from PARSEC 2.1 suite earlier for testing purpose. But now as I need to perform edits in the benchmarks, I'll have to compile them. I tried doing this using host machine (X86), but the application when run on simulated machine gave \texttt{glibc} version issue. \\
%\textbf{September Update}: \\
\indent The work of finding the dynamic instruction counts at \texttt{mutex\_unlock} accesses is in progress, I extracted the pcaddress for the function using objdump but it's not matching with any of the pcadresses used by the simulated machine. \\
Experiments on ILP-TLP trade-offs are being performed on the ARM-based simulated machine. I am facing the issue where I cross-compiled the benchmarks on host but they aren't being recognized as a binary leading to exec format error. I am working to fix this issue as well. Scripts for these experiments have been written.  
\section{Work to be done}
\begin{itemize}
   \item Experiments on ILP-TLP trade-offs: Running PARSEC benchmarks: with 4 threads on system with 4 2-way OoO cores; with 2 threads on system with 2 4-way OoO cores; with 1 thread (or serial) on system with 1 8-way OoO core. \textbf{Ongoing}
    \item Appropriate compilation of PARSEC 3.0 benchmarks for X86 ISA so that it works for gem5 simulated machine. (host machine compiled application gave \texttt{glibc} version issue on simulated machine) \textbf{Ongoing}
   \item Obtaining dynamic instruction count after every \texttt{mutex\_unlock} and dumping the simulation statistics. For this need to check the address of this function from disassembly of compiled binary, and check whenever this address is accessed and get the dynamic instruction count. \textbf{Ongoing}
%    \item Scripting files for running PARSEC benchmarks with varying number of threads and the underlying system configurations  
    \item Analysis of statistics for each phase run on each configuration to determine optima. Approximation of reconfiguration delays
\end{itemize}
%\section{Simulation Results}
%\chapter{Conclusion \& Future scope}
\bibliographystyle{ieeetr}
\bibliography{thesisTemplate}{}
\end{document}
